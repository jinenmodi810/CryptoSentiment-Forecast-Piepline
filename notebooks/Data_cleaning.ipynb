{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7ffa5b0-3973-487a-bdef-19b576f2c1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp313-cp313-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/homebrew/Cellar/jupyterlab/4.4.0/libexec/lib/python3.13/site-packages (from scikit-learn) (2.2.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.15.2-cp313-cp313-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.6.1-cp313-cp313-macosx_12_0_arm64.whl (11.1 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached scipy-1.15.2-cp313-cp313-macosx_14_0_arm64.whl (22.4 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/Cellar/jupyterlab/4.4.0/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c91e0647-93bc-4fe8-8bf6-1173c45b912d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¾ Available Columns:\n",
      "Index(['source', 'title', 'url', 'published_date', 'scraped_at', 'sentiment'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your cleaned file\n",
    "file_path = \"/Users/jinenmodi/ImpData/Crypto Sentiment Prediction/crypto_sentiment_project/data/crypto_news_with_sentiment.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Check column names\n",
    "print(\"ðŸ§¾ Available Columns:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b359e192-90ac-4c22-8619-450f02fe32df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Cellar/jupyterlab/4.4.0/libexec/lib/python3.13/site-packages (from vaderSentiment) (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/Cellar/jupyterlab/4.4.0/libexec/lib/python3.13/site-packages (from requests->vaderSentiment) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Cellar/jupyterlab/4.4.0/libexec/lib/python3.13/site-packages (from requests->vaderSentiment) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Cellar/jupyterlab/4.4.0/libexec/lib/python3.13/site-packages (from requests->vaderSentiment) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/opt/certifi/lib/python3.13/site-packages (from requests->vaderSentiment) (2025.1.31)\n",
      "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/Cellar/jupyterlab/4.4.0/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "050d42bf-79ca-46ab-b345-2eefe1de4db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "Neutral     1197\n",
      "Positive     635\n",
      "Negative     544\n",
      "Name: count, dtype: int64\n",
      "âœ… Sentiment-labeled data saved to: /Users/jinenmodi/ImpData/Crypto Sentiment Prediction/crypto_sentiment_project/data/crypto_news_with_sentiment.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# ðŸ“‚ Load the cleaned dataset\n",
    "file_path = \"/Users/jinenmodi/ImpData/Crypto Sentiment Prediction/crypto_sentiment_project/data/crypto_news_with_sentiment.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# ðŸ” Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# ðŸ§  Define function to classify sentiment\n",
    "def classify_sentiment(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return \"Neutral\"  # Handle empty or non-string entries\n",
    "    score = analyzer.polarity_scores(text)[\"compound\"]\n",
    "    if score >= 0.05:\n",
    "        return \"Positive\"\n",
    "    elif score <= -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# ðŸ·ï¸ Apply sentiment classification on 'title'\n",
    "df[\"sentiment\"] = df[\"title\"].apply(classify_sentiment)\n",
    "\n",
    "# ðŸ“Š Show sentiment counts\n",
    "print(df[\"sentiment\"].value_counts())\n",
    "\n",
    "# ðŸ’¾ Save the new file with sentiment column\n",
    "output_path = \"/Users/jinenmodi/ImpData/Crypto Sentiment Prediction/crypto_sentiment_project/data/crypto_news_with_sentiment.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"âœ… Sentiment-labeled data saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "241c8502-4f00-455f-acb3-12d944c22b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded successfully.\n",
      " Unique sentiment classes: ['Neutral' 'Negative' 'Positive']\n",
      "Label Mapping: {'Negative': np.int64(0), 'Neutral': np.int64(1), 'Positive': np.int64(2)}\n",
      "Encoded dataset saved to: /Users/jinenmodi/ImpData/Crypto Sentiment Prediction/crypto_sentiment_project/data/crypto_news_with_sentiment_encoded.xlsx\n",
      "\n",
      " Encoded Sample:\n",
      "  sentiment  sentiment_encoded\n",
      "0   Neutral                  1\n",
      "1   Neutral                  1\n",
      "2  Negative                  0\n",
      "3   Neutral                  1\n",
      "4  Negative                  0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load your cleaned Excel file\n",
    "file_path = \"/Users/jinenmodi/ImpData/Crypto Sentiment Prediction/crypto_sentiment_project/data/crypto_news_with_sentiment.xlsx\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_excel(file_path)\n",
    "    print(\"File loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"âŒ File not found at: {file_path}\")\n",
    "\n",
    "# Check if 'sentiment' column exists\n",
    "if 'sentiment' not in df.columns:\n",
    "    raise KeyError(\" 'sentiment' column not found. Please check your dataset.\")\n",
    "\n",
    "# Display unique sentiment values\n",
    "print(f\" Unique sentiment classes: {df['sentiment'].unique()}\")\n",
    "\n",
    "# Initialize and fit LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['sentiment_encoded'] = label_encoder.fit_transform(df['sentiment'].astype(str))\n",
    "\n",
    "# Create a mapping dictionary (for interpretation)\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Label Mapping:\", label_mapping)\n",
    "\n",
    "#  Save encoded DataFrame (optional)\n",
    "encoded_path = file_path.replace(\".xlsx\", \"_encoded.xlsx\")\n",
    "df.to_excel(encoded_path, index=False)\n",
    "print(f\"Encoded dataset saved to: {encoded_path}\")\n",
    "\n",
    "# Preview sample\n",
    "print(\"\\n Encoded Sample:\")\n",
    "print(df[['sentiment', 'sentiment_encoded']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a96ac678-087e-440c-8029-e203fc500f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.22      0.34        93\n",
      "           1       0.56      0.98      0.71       242\n",
      "           2       0.85      0.16      0.27       141\n",
      "\n",
      "    accuracy                           0.59       476\n",
      "   macro avg       0.75      0.45      0.44       476\n",
      "weighted avg       0.70      0.59      0.51       476\n",
      "\n",
      "Accuracy: 0.5903361344537815\n",
      "Confusion Matrix:\n",
      " [[ 20  70   3]\n",
      " [  3 238   1]\n",
      " [  1 117  23]]\n",
      " Model and vectorizer saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Step 1: Load the cleaned dataset\n",
    "file_path = \"/Users/jinenmodi/ImpData/Crypto Sentiment Prediction/crypto_sentiment_project/data/crypto_news_with_sentiment_encoded.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Step 2: Text Cleaning Function\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# Step 3: Apply cleaning\n",
    "df['clean_text'] = df['title'].astype(str).apply(clean_text)\n",
    "\n",
    "# Step 4: TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df['clean_text'])\n",
    "\n",
    "# Step 5: Labels\n",
    "y = df['sentiment_encoded']\n",
    "\n",
    "# Step 6: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 7: Model Training\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Step 9: Save model and vectorizer\n",
    "joblib.dump(model, \"sentiment_model_nb.pkl\")\n",
    "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n",
    "print(\" Model and vectorizer saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3e71c5-ac28-4d3a-9309-1763f8b4cfb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
