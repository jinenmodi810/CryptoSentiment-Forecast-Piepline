{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0fb07dc-cdd7-4bfd-8865-8ff434fa6e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Fetching r/CryptoCurrency page 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/14/lwdqxjmj54dcx0n3tktty0gw0000gn/T/ipykernel_42020/80405787.py:58: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  \"created_utc\": datetime.utcfromtimestamp(p.get(\"created_utc\", 0)).strftime('%Y-%m-%d %H:%M:%S'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Fetching r/CryptoCurrency page 2\n",
      "📦 Fetching r/CryptoCurrency page 3\n",
      "📦 Fetching r/CryptoCurrency page 4\n",
      "📦 Fetching r/CryptoCurrency page 5\n",
      "📦 Fetching r/CryptoCurrency page 6\n",
      "📦 Fetching r/CryptoCurrency page 7\n",
      "📦 Fetching r/CryptoCurrency page 8\n",
      "📦 Fetching r/CryptoCurrency page 9\n",
      "📦 Fetching r/CryptoCurrency page 10\n",
      "📦 Fetching r/CryptoCurrency page 11\n",
      "📦 Fetching r/CryptoCurrency page 12\n",
      "📦 Fetching r/CryptoCurrency page 13\n",
      "📦 Fetching r/CryptoCurrency page 14\n",
      "🚫 No more pages for r/CryptoCurrency\n",
      "📦 Fetching r/Bitcoin page 1\n",
      "📦 Fetching r/Bitcoin page 2\n",
      "📦 Fetching r/Bitcoin page 3\n",
      "📦 Fetching r/Bitcoin page 4\n",
      "📦 Fetching r/Bitcoin page 5\n",
      "📦 Fetching r/Bitcoin page 6\n",
      "📦 Fetching r/Bitcoin page 7\n",
      "📦 Fetching r/Bitcoin page 8\n",
      "📦 Fetching r/Bitcoin page 9\n",
      "📦 Fetching r/Bitcoin page 10\n",
      "📦 Fetching r/Bitcoin page 11\n",
      "📦 Fetching r/Bitcoin page 12\n",
      "📦 Fetching r/Bitcoin page 13\n",
      "📦 Fetching r/Bitcoin page 14\n",
      "📦 Fetching r/Bitcoin page 15\n",
      "📦 Fetching r/Bitcoin page 16\n",
      "📦 Fetching r/Bitcoin page 17\n",
      "📦 Fetching r/Bitcoin page 18\n",
      "📦 Fetching r/Bitcoin page 19\n",
      "📦 Fetching r/Bitcoin page 20\n",
      "📦 Fetching r/CryptoMarkets page 1\n",
      "📦 Fetching r/CryptoMarkets page 2\n",
      "📦 Fetching r/CryptoMarkets page 3\n",
      "📦 Fetching r/CryptoMarkets page 4\n",
      "📦 Fetching r/CryptoMarkets page 5\n",
      "📦 Fetching r/CryptoMarkets page 6\n",
      "📦 Fetching r/CryptoMarkets page 7\n",
      "📦 Fetching r/CryptoMarkets page 8\n",
      "📦 Fetching r/CryptoMarkets page 9\n",
      "📦 Fetching r/CryptoMarkets page 10\n",
      "📦 Fetching r/CryptoMarkets page 11\n",
      "📦 Fetching r/CryptoMarkets page 12\n",
      "📦 Fetching r/CryptoMarkets page 13\n",
      "📦 Fetching r/CryptoMarkets page 14\n",
      "📦 Fetching r/CryptoMarkets page 15\n",
      "📦 Fetching r/CryptoMarkets page 16\n",
      "📦 Fetching r/CryptoMarkets page 17\n",
      "📦 Fetching r/CryptoMarkets page 18\n",
      "📦 Fetching r/CryptoMarkets page 19\n",
      "📦 Fetching r/CryptoMarkets page 20\n",
      "📦 Fetching r/CryptoTechnology page 1\n",
      "📦 Fetching r/CryptoTechnology page 2\n",
      "📦 Fetching r/CryptoTechnology page 3\n",
      "📦 Fetching r/CryptoTechnology page 4\n",
      "📦 Fetching r/CryptoTechnology page 5\n",
      "📦 Fetching r/CryptoTechnology page 6\n",
      "📦 Fetching r/CryptoTechnology page 7\n",
      "🚫 No more pages for r/CryptoTechnology\n",
      "📦 Fetching r/CryptoNews page 1\n",
      "📦 Fetching r/CryptoNews page 2\n",
      "📦 Fetching r/CryptoNews page 3\n",
      "📦 Fetching r/CryptoNews page 4\n",
      "📦 Fetching r/CryptoNews page 5\n",
      "📦 Fetching r/CryptoNews page 6\n",
      "🚫 No more pages for r/CryptoNews\n",
      "✅ Collected 1625 total posts across 5 subreddits.\n",
      "        subreddit                                              title  \\\n",
      "0  CryptoCurrency  PSA: The Moons Discord is now r/CryptoCurrency...   \n",
      "1  CryptoCurrency   Daily Crypto Discussion - April 29, 2025 (GMT+0)   \n",
      "2  CryptoCurrency                    Waking Up After 7 Years Like...   \n",
      "3  CryptoCurrency                          \"What shall we do, sire?\"   \n",
      "4  CryptoCurrency                                  Food for thought…   \n",
      "\n",
      "                 author          created_utc  score  num_comments  \\\n",
      "0      CryptoMaximalist  2025-04-25 00:19:49     15            16   \n",
      "1          CryptoDaily-  2025-04-29 00:00:45      3            10   \n",
      "2             kirtash93  2025-04-28 12:04:20   3641            92   \n",
      "3  InclineDumbbellPress  2025-04-28 22:26:16    312            13   \n",
      "4    Silver-Maximum9190  2025-04-28 17:23:30    700           208   \n",
      "\n",
      "                                                 url detected_coins  \n",
      "0  https://www.reddit.com/r/CryptoCurrency/commen...        unknown  \n",
      "1  https://www.reddit.com/r/CryptoCurrency/commen...        unknown  \n",
      "2                https://i.redd.it/f7rlteh6gkxe1.png        unknown  \n",
      "3                https://i.redd.it/fbs2dzfxinxe1.png        unknown  \n",
      "4               https://i.redd.it/8qgo0mv41mxe1.jpeg        unknown  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# 📚 Define keywords for coins\n",
    "coin_keywords = {\n",
    "    \"bitcoin\": [\"bitcoin\", \"btc\"],\n",
    "    \"ethereum\": [\"ethereum\", \"eth\"],\n",
    "    \"solana\": [\"solana\", \"sol\"],\n",
    "    \"cardano\": [\"cardano\", \"ada\"],\n",
    "    \"dogecoin\": [\"dogecoin\", \"doge\"],\n",
    "    \"ripple\": [\"ripple\", \"xrp\"],\n",
    "    \"litecoin\": [\"litecoin\", \"ltc\"],\n",
    "    \"polkadot\": [\"polkadot\", \"dot\"],\n",
    "    \"chainlink\": [\"chainlink\", \"link\"],\n",
    "    \"polygon\": [\"polygon\", \"matic\"]\n",
    "}\n",
    "\n",
    "def detect_coin(title):\n",
    "    title_lower = title.lower()\n",
    "    detected_coins = []\n",
    "    for coin, keywords in coin_keywords.items():\n",
    "        for keyword in keywords:\n",
    "            if keyword in title_lower:\n",
    "                detected_coins.append(coin)\n",
    "                break  # No need to check further if one keyword matched\n",
    "    return detected_coins if detected_coins else [\"unknown\"]\n",
    "\n",
    "def scrape_reddit(subreddit=\"CryptoCurrency\", pages=20, delay=2):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    after = None\n",
    "    posts = []\n",
    "\n",
    "    for page in range(pages):\n",
    "        url = f\"https://www.reddit.com/r/{subreddit}/.json\"\n",
    "        if after:\n",
    "            url += f\"?after={after}\"\n",
    "\n",
    "        print(f\"📦 Fetching r/{subreddit} page {page + 1}\")\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"❌ Failed at page {page + 1} | Status:\", response.status_code)\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "        children = data[\"data\"][\"children\"]\n",
    "        after = data[\"data\"].get(\"after\", None)\n",
    "\n",
    "        for post in children:\n",
    "            p = post[\"data\"]\n",
    "            title = p.get(\"title\", \"\")\n",
    "            coin_tags = detect_coin(title)\n",
    "            posts.append({\n",
    "                \"subreddit\": subreddit,\n",
    "                \"title\": title,\n",
    "                \"author\": p.get(\"author\", \"\"),\n",
    "                \"created_utc\": datetime.utcfromtimestamp(p.get(\"created_utc\", 0)).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                \"score\": p.get(\"score\", 0),\n",
    "                \"num_comments\": p.get(\"num_comments\", 0),\n",
    "                \"url\": p.get(\"url\", \"\"),\n",
    "                \"detected_coins\": \", \".join(coin_tags)  # Store detected coins\n",
    "            })\n",
    "\n",
    "        if not after:\n",
    "            print(f\"🚫 No more pages for r/{subreddit}\")\n",
    "            break\n",
    "\n",
    "        time.sleep(delay)\n",
    "\n",
    "    return posts\n",
    "\n",
    "# 🔁 Combine from multiple subreddits\n",
    "if __name__ == \"__main__\":\n",
    "    all_subreddits = [\"CryptoCurrency\", \"Bitcoin\", \"CryptoMarkets\", \"CryptoTechnology\", \"CryptoNews\"]\n",
    "    all_posts = []\n",
    "\n",
    "    for sub in all_subreddits:\n",
    "        posts = scrape_reddit(subreddit=sub, pages=20)\n",
    "        all_posts.extend(posts)\n",
    "\n",
    "    df = pd.DataFrame(all_posts)\n",
    "    df.drop_duplicates(subset=[\"title\", \"url\"], inplace=True)\n",
    "    df.to_csv(\"reddit_crypto_bulk_tagged.csv\", index=False)\n",
    "\n",
    "    print(f\"✅ Collected {len(df)} total posts across {len(all_subreddits)} subreddits.\")\n",
    "    print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c6c32e0-d361-4173-8b63-8e31031e5218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Starting r/CryptoCurrency...\n",
      "📦 Fetching page 1 of r/CryptoCurrency\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/14/lwdqxjmj54dcx0n3tktty0gw0000gn/T/ipykernel_42020/2463813547.py:57: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  \"created_utc\": datetime.utcfromtimestamp(p.get(\"created_utc\", 0)).strftime('%Y-%m-%d %H:%M:%S'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Fetching page 2 of r/CryptoCurrency\n",
      "📦 Fetching page 3 of r/CryptoCurrency\n",
      "📦 Fetching page 4 of r/CryptoCurrency\n",
      "📦 Fetching page 5 of r/CryptoCurrency\n",
      "📦 Fetching page 6 of r/CryptoCurrency\n",
      "📦 Fetching page 7 of r/CryptoCurrency\n",
      "📦 Fetching page 8 of r/CryptoCurrency\n",
      "📦 Fetching page 9 of r/CryptoCurrency\n",
      "📦 Fetching page 10 of r/CryptoCurrency\n",
      "📦 Fetching page 11 of r/CryptoCurrency\n",
      "📦 Fetching page 12 of r/CryptoCurrency\n",
      "📦 Fetching page 13 of r/CryptoCurrency\n",
      "🚫 No more pages.\n",
      "\n",
      "🚀 Starting r/Bitcoin...\n",
      "📦 Fetching page 1 of r/Bitcoin\n",
      "📦 Fetching page 2 of r/Bitcoin\n",
      "📦 Fetching page 3 of r/Bitcoin\n",
      "📦 Fetching page 4 of r/Bitcoin\n",
      "📦 Fetching page 5 of r/Bitcoin\n",
      "📦 Fetching page 6 of r/Bitcoin\n",
      "📦 Fetching page 7 of r/Bitcoin\n",
      "📦 Fetching page 8 of r/Bitcoin\n",
      "📦 Fetching page 9 of r/Bitcoin\n",
      "📦 Fetching page 10 of r/Bitcoin\n",
      "📦 Fetching page 11 of r/Bitcoin\n",
      "📦 Fetching page 12 of r/Bitcoin\n",
      "📦 Fetching page 13 of r/Bitcoin\n",
      "📦 Fetching page 14 of r/Bitcoin\n",
      "📦 Fetching page 15 of r/Bitcoin\n",
      "📦 Fetching page 16 of r/Bitcoin\n",
      "📦 Fetching page 17 of r/Bitcoin\n",
      "📦 Fetching page 18 of r/Bitcoin\n",
      "📦 Fetching page 19 of r/Bitcoin\n",
      "📦 Fetching page 20 of r/Bitcoin\n",
      "\n",
      "🚀 Starting r/CryptoMarkets...\n",
      "📦 Fetching page 1 of r/CryptoMarkets\n",
      "📦 Fetching page 2 of r/CryptoMarkets\n",
      "📦 Fetching page 3 of r/CryptoMarkets\n",
      "📦 Fetching page 4 of r/CryptoMarkets\n",
      "📦 Fetching page 5 of r/CryptoMarkets\n",
      "📦 Fetching page 6 of r/CryptoMarkets\n",
      "📦 Fetching page 7 of r/CryptoMarkets\n",
      "📦 Fetching page 8 of r/CryptoMarkets\n",
      "📦 Fetching page 9 of r/CryptoMarkets\n",
      "📦 Fetching page 10 of r/CryptoMarkets\n",
      "📦 Fetching page 11 of r/CryptoMarkets\n",
      "📦 Fetching page 12 of r/CryptoMarkets\n",
      "📦 Fetching page 13 of r/CryptoMarkets\n",
      "📦 Fetching page 14 of r/CryptoMarkets\n",
      "📦 Fetching page 15 of r/CryptoMarkets\n",
      "📦 Fetching page 16 of r/CryptoMarkets\n",
      "📦 Fetching page 17 of r/CryptoMarkets\n",
      "📦 Fetching page 18 of r/CryptoMarkets\n",
      "📦 Fetching page 19 of r/CryptoMarkets\n",
      "📦 Fetching page 20 of r/CryptoMarkets\n",
      "\n",
      "🚀 Starting r/CryptoTechnology...\n",
      "📦 Fetching page 1 of r/CryptoTechnology\n",
      "📦 Fetching page 2 of r/CryptoTechnology\n",
      "📦 Fetching page 3 of r/CryptoTechnology\n",
      "📦 Fetching page 4 of r/CryptoTechnology\n",
      "📦 Fetching page 5 of r/CryptoTechnology\n",
      "📦 Fetching page 6 of r/CryptoTechnology\n",
      "📦 Fetching page 7 of r/CryptoTechnology\n",
      "🚫 No more pages.\n",
      "\n",
      "🚀 Starting r/CryptoNews...\n",
      "📦 Fetching page 1 of r/CryptoNews\n",
      "📦 Fetching page 2 of r/CryptoNews\n",
      "📦 Fetching page 3 of r/CryptoNews\n",
      "📦 Fetching page 4 of r/CryptoNews\n",
      "📦 Fetching page 5 of r/CryptoNews\n",
      "📦 Fetching page 6 of r/CryptoNews\n",
      "🚫 No more pages.\n",
      "\n",
      "✅ DONE: Collected 1621 Reddit posts total across 5 subs.\n",
      "          subreddit                                              title  \\\n",
      "1114  CryptoMarkets   Not Boom Time Folks, Just Another Dip Coming Up!   \n",
      "456         Bitcoin                                       Been forever   \n",
      "1556     CryptoNews  4 Reasons Why KuCoin’s KCS Loyalty Level Progr...   \n",
      "561         Bitcoin                                         The Irony!   \n",
      "1018  CryptoMarkets  Just wanna share an AI project that I did to a...   \n",
      "\n",
      "                 author          created_utc  score  num_comments  \\\n",
      "1114  Useful_Hippo_7801  2025-04-12 17:18:37     12            62   \n",
      "456              crrdlx  2025-04-27 22:27:33      5             8   \n",
      "1556           Hot_jems  2025-03-30 13:33:24      1             0   \n",
      "561         SodanReddit  2025-04-25 14:00:42     65            20   \n",
      "1018           kareee98  2025-04-18 12:00:21      0             5   \n",
      "\n",
      "                                                    url crypto_name  \n",
      "1114  https://www.reddit.com/r/CryptoMarkets/comment...     Unknown  \n",
      "456   https://www.reddit.com/r/Bitcoin/comments/1k9g...     Unknown  \n",
      "1556  https://bitcoinist.com/4-reasons-why-kucoins-k...     Unknown  \n",
      "561   https://www.reddit.com/r/Bitcoin/comments/1k7l...     Unknown  \n",
      "1018  https://www.reddit.com/r/CryptoMarkets/comment...     Unknown  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Define keyword-to-crypto mappings\n",
    "CRYPTO_KEYWORDS = {\n",
    "    \"Bitcoin\": [\"bitcoin\", \"btc\"],\n",
    "    \"Ethereum\": [\"ethereum\", \"eth\"],\n",
    "    \"Solana\": [\"solana\", \"sol\"],\n",
    "    \"Cardano\": [\"cardano\", \"ada\"],\n",
    "    \"Ripple\": [\"ripple\", \"xrp\"],\n",
    "    \"Dogecoin\": [\"dogecoin\", \"doge\"],\n",
    "    \"Polkadot\": [\"polkadot\", \"dot\"],\n",
    "    \"Chainlink\": [\"chainlink\", \"link\"],\n",
    "    \"Litecoin\": [\"litecoin\", \"ltc\"]\n",
    "}\n",
    "\n",
    "def detect_crypto(title):\n",
    "    title_lower = title.lower()\n",
    "    for crypto_name, keywords in CRYPTO_KEYWORDS.items():\n",
    "        if any(keyword in title_lower for keyword in keywords):\n",
    "            return crypto_name\n",
    "    return \"Unknown\"\n",
    "\n",
    "def scrape_reddit_bulk(subreddits, pages_per_sub=20, delay=2):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    all_posts = []\n",
    "\n",
    "    for subreddit in subreddits:\n",
    "        after = None\n",
    "        print(f\"\\n🚀 Starting r/{subreddit}...\")\n",
    "        for page in range(pages_per_sub):\n",
    "            url = f\"https://www.reddit.com/r/{subreddit}/.json\"\n",
    "            if after:\n",
    "                url += f\"?after={after}\"\n",
    "\n",
    "            print(f\"📦 Fetching page {page + 1} of r/{subreddit}\")\n",
    "            response = requests.get(url, headers=headers)\n",
    "            if response.status_code != 200:\n",
    "                print(f\"❌ Failed at page {page + 1} | Status Code:\", response.status_code)\n",
    "                break\n",
    "\n",
    "            data = response.json()\n",
    "            posts = data[\"data\"][\"children\"]\n",
    "            after = data[\"data\"].get(\"after\", None)\n",
    "\n",
    "            for post in posts:\n",
    "                p = post[\"data\"]\n",
    "                title = p.get(\"title\", \"\")\n",
    "                crypto_detected = detect_crypto(title)\n",
    "\n",
    "                all_posts.append({\n",
    "                    \"subreddit\": subreddit,\n",
    "                    \"title\": title,\n",
    "                    \"author\": p.get(\"author\", \"\"),\n",
    "                    \"created_utc\": datetime.utcfromtimestamp(p.get(\"created_utc\", 0)).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    \"score\": p.get(\"score\", 0),\n",
    "                    \"num_comments\": p.get(\"num_comments\", 0),\n",
    "                    \"url\": p.get(\"url\", \"\"),\n",
    "                    \"crypto_name\": crypto_detected\n",
    "                })\n",
    "\n",
    "            if not after:\n",
    "                print(\"🚫 No more pages.\")\n",
    "                break\n",
    "            time.sleep(delay)\n",
    "\n",
    "    return pd.DataFrame(all_posts)\n",
    "\n",
    "# 🔁 Run the collector\n",
    "if __name__ == \"__main__\":\n",
    "    target_subreddits = [\n",
    "        \"CryptoCurrency\",\n",
    "        \"Bitcoin\",\n",
    "        \"CryptoMarkets\",\n",
    "        \"CryptoTechnology\",\n",
    "        \"CryptoNews\"\n",
    "    ]\n",
    "\n",
    "    df = scrape_reddit_bulk(target_subreddits, pages_per_sub=20)\n",
    "    df.drop_duplicates(subset=[\"title\", \"url\"], inplace=True)\n",
    "    df.to_csv(\"reddit_crypto_2000_posts.csv\", index=False)\n",
    "\n",
    "    print(f\"\\n✅ DONE: Collected {len(df)} Reddit posts total across {len(target_subreddits)} subs.\")\n",
    "    print(df.sample(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f4b6425-7da8-4032-b44b-79f3bc6fc3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌐 Opening: https://cointelegraph.com/tags/bitcoin\n",
      "📜 Scroll 1/150\n",
      "📜 Scroll 2/150\n",
      "📜 Scroll 3/150\n",
      "📜 Scroll 4/150\n",
      "📜 Scroll 5/150\n",
      "📜 Scroll 6/150\n",
      "📜 Scroll 7/150\n",
      "📜 Scroll 8/150\n",
      "📜 Scroll 9/150\n",
      "📜 Scroll 10/150\n",
      "📜 Scroll 11/150\n",
      "📜 Scroll 12/150\n",
      "📜 Scroll 13/150\n",
      "📜 Scroll 14/150\n",
      "📜 Scroll 15/150\n",
      "📜 Scroll 16/150\n",
      "📜 Scroll 17/150\n",
      "📜 Scroll 18/150\n",
      "📜 Scroll 19/150\n",
      "📜 Scroll 20/150\n",
      "📜 Scroll 21/150\n",
      "📜 Scroll 22/150\n",
      "📜 Scroll 23/150\n",
      "📜 Scroll 24/150\n",
      "📜 Scroll 25/150\n",
      "📜 Scroll 26/150\n",
      "📜 Scroll 27/150\n",
      "📜 Scroll 28/150\n",
      "📜 Scroll 29/150\n",
      "📜 Scroll 30/150\n",
      "🚫 Reached end of page.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/14/lwdqxjmj54dcx0n3tktty0gw0000gn/T/ipykernel_42020/3306468351.py:74: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"scraped_at\": datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Scraped 450 Bitcoin articles from CoinTelegraph\n",
      "            source      tag  \\\n",
      "381  CoinTelegraph  bitcoin   \n",
      "379  CoinTelegraph  bitcoin   \n",
      "357  CoinTelegraph  bitcoin   \n",
      "46   CoinTelegraph  bitcoin   \n",
      "440  CoinTelegraph  bitcoin   \n",
      "\n",
      "                                              headline  \\\n",
      "381  Bitcoin breaks $86K as US tariff 'Liberation D...   \n",
      "379  Price analysis 4/2: BTC, ETH, XRP, BNB, SOL, D...   \n",
      "357  Malta regulator fines OKX crypto exchange $1.2...   \n",
      "46   Bitcoin ETFs on $3B ‘bender,’ log first full w...   \n",
      "440  Bitcoin price drops 3% on hot US PCE data as a...   \n",
      "\n",
      "                                                   url           scraped_at  \\\n",
      "381  https://cointelegraph.com/news/bitcoin-price-8...  2025-04-30 03:57:17   \n",
      "379  https://cointelegraph.com/news/price-analysis-...  2025-04-30 03:57:17   \n",
      "357  https://cointelegraph.com/news/malta-fines-okx...  2025-04-30 03:57:17   \n",
      "46   https://cointelegraph.com/news/us-spot-bitcoin...  2025-04-30 03:57:17   \n",
      "440  https://cointelegraph.com/news/bitcoin-price-d...  2025-04-30 03:57:17   \n",
      "\n",
      "    crypto_name  \n",
      "381     Bitcoin  \n",
      "379     Bitcoin  \n",
      "357     Unknown  \n",
      "46      Bitcoin  \n",
      "440     Bitcoin  \n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Keyword mapping to detect crypto name from headline\n",
    "CRYPTO_KEYWORDS = {\n",
    "    \"Bitcoin\": [\"bitcoin\", \"btc\"],\n",
    "    \"Ethereum\": [\"ethereum\", \"eth\"],\n",
    "    \"Solana\": [\"solana\", \"sol\"],\n",
    "    \"Cardano\": [\"cardano\", \"ada\"],\n",
    "    \"Ripple\": [\"ripple\", \"xrp\"],\n",
    "    \"Dogecoin\": [\"dogecoin\", \"doge\"],\n",
    "    \"Polkadot\": [\"polkadot\", \"dot\"],\n",
    "    \"Chainlink\": [\"chainlink\", \"link\"],\n",
    "    \"Litecoin\": [\"litecoin\", \"ltc\"]\n",
    "}\n",
    "\n",
    "def detect_crypto(text):\n",
    "    text = text.lower()\n",
    "    for name, keywords in CRYPTO_KEYWORDS.items():\n",
    "        if any(keyword in text for keyword in keywords):\n",
    "            return name\n",
    "    return \"Unknown\"\n",
    "\n",
    "def scroll_to_bottom(driver, scrolls=100, delay=2):\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    for i in range(scrolls):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(delay)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        print(f\"📜 Scroll {i+1}/{scrolls}\")\n",
    "        if new_height == last_height:\n",
    "            print(\"🚫 Reached end of page.\")\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "def scrape_cointelegraph_bitcoin_articles():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0\")\n",
    "\n",
    "    driver_path = \"/opt/homebrew/bin/chromedriver\"  # Adjust if needed\n",
    "    service = Service(driver_path)\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    url = \"https://cointelegraph.com/tags/bitcoin\"\n",
    "    print(f\"🌐 Opening: {url}\")\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    scroll_to_bottom(driver, scrolls=150, delay=2)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    links = soup.select(\"a.post-card-inline__title-link\")\n",
    "\n",
    "    articles = []\n",
    "    for a in links:\n",
    "        headline = a.text.strip()\n",
    "        href = a.get(\"href\", \"\")\n",
    "        if headline and href:\n",
    "            full_url = \"https://cointelegraph.com\" + href if href.startswith(\"/\") else href\n",
    "            crypto_detected = detect_crypto(headline)\n",
    "            articles.append({\n",
    "                \"source\": \"CoinTelegraph\",\n",
    "                \"tag\": \"bitcoin\",\n",
    "                \"headline\": headline,\n",
    "                \"url\": full_url,\n",
    "                \"scraped_at\": datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"crypto_name\": crypto_detected\n",
    "            })\n",
    "\n",
    "    driver.quit()\n",
    "    return pd.DataFrame(articles)\n",
    "\n",
    "# Run it\n",
    "if __name__ == \"__main__\":\n",
    "    df = scrape_cointelegraph_bitcoin_articles()\n",
    "    df.drop_duplicates(subset=\"url\", inplace=True)\n",
    "    df.to_excel(\"cointelegraph_bitcoin_scroll_fixed.xlsx\", index=False)\n",
    "\n",
    "    print(f\"\\n✅ Scraped {len(df)} Bitcoin articles from CoinTelegraph\")\n",
    "    print(df.sample(min(5, len(df))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2289502e-7699-4c68-b136-4b3fe0cf9ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Fetching page 1: https://cryptoslate.com/wp-json/wp/v2/posts?page=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/14/lwdqxjmj54dcx0n3tktty0gw0000gn/T/ipykernel_42020/931769044.py:57: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"scraped_at\": datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Fetching page 2: https://cryptoslate.com/wp-json/wp/v2/posts?page=2\n",
      "🔄 Fetching page 3: https://cryptoslate.com/wp-json/wp/v2/posts?page=3\n",
      "🔄 Fetching page 4: https://cryptoslate.com/wp-json/wp/v2/posts?page=4\n",
      "🔄 Fetching page 5: https://cryptoslate.com/wp-json/wp/v2/posts?page=5\n",
      "🔄 Fetching page 6: https://cryptoslate.com/wp-json/wp/v2/posts?page=6\n",
      "🔄 Fetching page 7: https://cryptoslate.com/wp-json/wp/v2/posts?page=7\n",
      "🔄 Fetching page 8: https://cryptoslate.com/wp-json/wp/v2/posts?page=8\n",
      "🔄 Fetching page 9: https://cryptoslate.com/wp-json/wp/v2/posts?page=9\n",
      "🔄 Fetching page 10: https://cryptoslate.com/wp-json/wp/v2/posts?page=10\n",
      "🔄 Fetching page 11: https://cryptoslate.com/wp-json/wp/v2/posts?page=11\n",
      "🔄 Fetching page 12: https://cryptoslate.com/wp-json/wp/v2/posts?page=12\n",
      "🔄 Fetching page 13: https://cryptoslate.com/wp-json/wp/v2/posts?page=13\n",
      "🔄 Fetching page 14: https://cryptoslate.com/wp-json/wp/v2/posts?page=14\n",
      "🔄 Fetching page 15: https://cryptoslate.com/wp-json/wp/v2/posts?page=15\n",
      "🔄 Fetching page 16: https://cryptoslate.com/wp-json/wp/v2/posts?page=16\n",
      "🔄 Fetching page 17: https://cryptoslate.com/wp-json/wp/v2/posts?page=17\n",
      "🔄 Fetching page 18: https://cryptoslate.com/wp-json/wp/v2/posts?page=18\n",
      "🔄 Fetching page 19: https://cryptoslate.com/wp-json/wp/v2/posts?page=19\n",
      "🔄 Fetching page 20: https://cryptoslate.com/wp-json/wp/v2/posts?page=20\n",
      "🔄 Fetching page 21: https://cryptoslate.com/wp-json/wp/v2/posts?page=21\n",
      "🔄 Fetching page 22: https://cryptoslate.com/wp-json/wp/v2/posts?page=22\n",
      "🔄 Fetching page 23: https://cryptoslate.com/wp-json/wp/v2/posts?page=23\n",
      "🔄 Fetching page 24: https://cryptoslate.com/wp-json/wp/v2/posts?page=24\n",
      "🔄 Fetching page 25: https://cryptoslate.com/wp-json/wp/v2/posts?page=25\n",
      "✅ Saved 250 articles to cryptoslate_articles_wpapi.xlsx\n",
      "                                                 title  \\\n",
      "89   Gold’s trillion‑dollar climb shows Bitcoin has...   \n",
      "210  ‘We don’t care,” states Chinese official upon ...   \n",
      "230  SEC and Ripple file joint motion to pause appe...   \n",
      "240  Magic Eden acquires Slingshot to expand into o...   \n",
      "19   Arizona legislature passes Bitcoin reserve bil...   \n",
      "\n",
      "                                                  link                 date  \\\n",
      "89   https://cryptoslate.com/golds-trillion%e2%80%9...  2025-04-23T02:00:24   \n",
      "210  https://cryptoslate.com/we-dont-care-states-ch...  2025-04-12T12:38:27   \n",
      "230  https://cryptoslate.com/sec-and-ripple-file-jo...  2025-04-10T22:30:31   \n",
      "240  https://cryptoslate.com/magic-eden-acquires-sl...  2025-04-10T01:30:36   \n",
      "19   https://cryptoslate.com/arizona-legislature-pa...  2025-04-28T23:16:21   \n",
      "\n",
      "              scraped_at crypto_name  \n",
      "89   2025-04-30 04:09:49     Bitcoin  \n",
      "210  2025-04-30 04:10:12     Unknown  \n",
      "230  2025-04-30 04:10:15      Ripple  \n",
      "240  2025-04-30 04:10:16     Unknown  \n",
      "19   2025-04-30 04:09:38     Bitcoin  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Keyword mapping to detect crypto names\n",
    "CRYPTO_KEYWORDS = {\n",
    "    \"Bitcoin\": [\"bitcoin\", \"btc\"],\n",
    "    \"Ethereum\": [\"ethereum\", \"eth\"],\n",
    "    \"Solana\": [\"solana\", \"sol\"],\n",
    "    \"Cardano\": [\"cardano\", \"ada\"],\n",
    "    \"Ripple\": [\"ripple\", \"xrp\"],\n",
    "    \"Dogecoin\": [\"dogecoin\", \"doge\"],\n",
    "    \"Polkadot\": [\"polkadot\", \"dot\"],\n",
    "    \"Chainlink\": [\"chainlink\", \"link\"],\n",
    "    \"Litecoin\": [\"litecoin\", \"ltc\"],\n",
    "    \"Binance Coin\": [\"binance\", \"bnb\"]\n",
    "}\n",
    "\n",
    "def detect_crypto(title):\n",
    "    \"\"\"Detect crypto name based on title text.\"\"\"\n",
    "    title = title.lower()\n",
    "    for crypto_name, keywords in CRYPTO_KEYWORDS.items():\n",
    "        if any(keyword in title for keyword in keywords):\n",
    "            return crypto_name\n",
    "    return \"Unknown\"\n",
    "\n",
    "def scrape_cryptoslate_wpapi(pages=10):\n",
    "    base_url = \"https://cryptoslate.com/wp-json/wp/v2/posts?page={}\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "\n",
    "    all_articles = []\n",
    "\n",
    "    for page in range(1, pages + 1):\n",
    "        url = base_url.format(page)\n",
    "        print(f\"🔄 Fetching page {page}: {url}\")\n",
    "        resp = requests.get(url, headers=headers)\n",
    "\n",
    "        if resp.status_code != 200:\n",
    "            print(f\"❌ Failed at page {page} | Status {resp.status_code}\")\n",
    "            break\n",
    "\n",
    "        data = resp.json()\n",
    "        if not data:\n",
    "            print(\"🚫 No data returned.\")\n",
    "            break\n",
    "\n",
    "        for item in data:\n",
    "            title = item.get(\"title\", {}).get(\"rendered\", \"\")\n",
    "            detected = detect_crypto(title)\n",
    "            all_articles.append({\n",
    "                \"title\": title,\n",
    "                \"link\": item.get(\"link\", \"\"),\n",
    "                \"date\": item.get(\"date\", \"\"),\n",
    "                \"scraped_at\": datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"crypto_name\": detected\n",
    "            })\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "    return pd.DataFrame(all_articles)\n",
    "\n",
    "# ✅ Run it\n",
    "if __name__ == \"__main__\":\n",
    "    df = scrape_cryptoslate_wpapi(pages=25)\n",
    "    df.to_excel(\"cryptoslate_articles_wpapi.xlsx\", index=False)\n",
    "    print(f\"✅ Saved {len(df)} articles to cryptoslate_articles_wpapi.xlsx\")\n",
    "    print(df.sample(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81e91d40-4811-404f-b576-f27d7049ce06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Scraping price for Bitcoin...\n",
      "🔍 Scraping price for Ethereum...\n",
      "🔍 Scraping price for Solana...\n",
      "🔍 Scraping price for Cardano...\n",
      "🔍 Scraping price for Ripple...\n",
      "🔍 Scraping price for Dogecoin...\n",
      "🔍 Scraping price for Polkadot...\n",
      "🔍 Scraping price for Chainlink...\n",
      "🔍 Scraping price for Litecoin...\n",
      "🔍 Scraping price for Binance Coin...\n",
      "✅ Prices saved to crypto_prices.csv\n",
      "    crypto_name price_usd\n",
      "0       Bitcoin      None\n",
      "1      Ethereum      None\n",
      "2        Solana      None\n",
      "3       Cardano      None\n",
      "4        Ripple      None\n",
      "5      Dogecoin      None\n",
      "6      Polkadot      None\n",
      "7     Chainlink      None\n",
      "8      Litecoin      None\n",
      "9  Binance Coin      None\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "cryptos = {\n",
    "    \"Bitcoin\": \"bitcoin\",\n",
    "    \"Ethereum\": \"ethereum\",\n",
    "    \"Solana\": \"solana\",\n",
    "    \"Cardano\": \"cardano\",\n",
    "    \"Ripple\": \"ripple\",\n",
    "    \"Dogecoin\": \"dogecoin\",\n",
    "    \"Polkadot\": \"polkadot\",\n",
    "    \"Chainlink\": \"chainlink\",\n",
    "    \"Litecoin\": \"litecoin\",\n",
    "    \"Binance Coin\": \"binancecoin\"\n",
    "}\n",
    "\n",
    "def get_price(slug):\n",
    "    url = f\"https://www.coingecko.com/en/coins/{slug}\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "    price_tag = soup.select_one(\"span[data-target='price.price']\")\n",
    "    if not price_tag:\n",
    "        price_tag = soup.select_one(\".no-wrap\")\n",
    "    \n",
    "    try:\n",
    "        price = price_tag.text.strip().replace(\"$\", \"\").replace(\",\", \"\")\n",
    "        return float(price)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def scrape_prices():\n",
    "    results = []\n",
    "    for name, slug in cryptos.items():\n",
    "        print(f\"🔍 Scraping price for {name}...\")\n",
    "        price = get_price(slug)\n",
    "        results.append({\"crypto_name\": name, \"price_usd\": price})\n",
    "        time.sleep(2)  # to avoid rate-limiting\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = scrape_prices()\n",
    "    df.to_csv(\"crypto_prices.csv\", index=False)\n",
    "    print(\"✅ Prices saved to crypto_prices.csv\")\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "797f91bf-0aa7-4939-a4b6-fa68274776e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 23:45:39,525 INFO [scraper] Starting scrape of 10 coins with 5 workers\n",
      "2025-04-29 23:45:41,161 INFO [scraper] Done. Results written to crypto_prices.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import argparse\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# ─── CONFIGURE LOGGING ─────────────────────────────────────────────────────────\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s [%(name)s] %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(\"scraper\")\n",
    "\n",
    "# ─── UTILITIES ──────────────────────────────────────────────────────────────────\n",
    "def convert_abbrev(value_str):\n",
    "    \"\"\"\n",
    "    Convert strings with K/M/B/T suffix to float.\n",
    "    E.g. '3.5K'->3500, '2.1M'->2100000, '3.077T'->3077000000000\n",
    "    \"\"\"\n",
    "    multipliers = {\"K\": 1e3, \"M\": 1e6, \"B\": 1e9, \"T\": 1e12}\n",
    "    if not value_str:\n",
    "        return None\n",
    "    suffix = value_str[-1].upper()\n",
    "    try:\n",
    "        if suffix in multipliers:\n",
    "            num = float(value_str[:-1].replace(\",\", \"\"))\n",
    "            return num * multipliers[suffix]\n",
    "        return float(value_str.replace(\",\", \"\"))\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# ─── PARSERS ────────────────────────────────────────────────────────────────────\n",
    "def parse_price(soup):\n",
    "    \"\"\"\n",
    "    Grabs the first <span class=\"no-wrap\">…</span>,\n",
    "    which always contains the USD price (e.g. \"$64,321.12\").\n",
    "    \"\"\"\n",
    "    tag = soup.select_one(\"span.no-wrap\")\n",
    "    if tag:\n",
    "        match = re.search(r\"\\$\\s*([\\d,]+\\.?\\d*)\", tag.text)\n",
    "        if match:\n",
    "            return float(match.group(1).replace(\",\", \"\"))\n",
    "    return None\n",
    "\n",
    "def parse_change_24h(soup):\n",
    "    tag = soup.select_one('span[data-target=\"percent-change.percent\"]')\n",
    "    if tag:\n",
    "        return float(tag.text.strip().replace(\"%\", \"\").replace(\",\", \"\"))\n",
    "    return None\n",
    "\n",
    "def parse_market_cap(soup):\n",
    "    tag = soup.select_one('div[data-target=\"metric-market-cap.number\"], span[data-target=\"price.market_cap\"]')\n",
    "    if tag:\n",
    "        text = tag.text.strip().replace(\"$\", \"\")\n",
    "        return convert_abbrev(text)\n",
    "    return None\n",
    "\n",
    "def parse_volume_24h(soup):\n",
    "    tag = soup.select_one('div[data-target=\"metric-volume.number\"], span[data-target=\"price.total_volume\"]')\n",
    "    if tag:\n",
    "        text = tag.text.strip().replace(\"$\", \"\")\n",
    "        return convert_abbrev(text)\n",
    "    return None\n",
    "\n",
    "# ─── WORKER ─────────────────────────────────────────────────────────────────────\n",
    "def get_coin_data(name, slug, session, retries=3):\n",
    "    url = f\"https://www.coingecko.com/en/coins/{slug}\"\n",
    "    backoff = 1\n",
    "    for attempt in range(1, retries + 1):\n",
    "        try:\n",
    "            resp = session.get(url, timeout=10)\n",
    "            resp.raise_for_status()\n",
    "            soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "            return {\n",
    "                \"crypto_name\":    name,\n",
    "                \"price_usd\":      parse_price(soup),\n",
    "                \"change_24h\":     parse_change_24h(soup),\n",
    "                \"market_cap_usd\": parse_market_cap(soup),\n",
    "                \"volume_24h_usd\": parse_volume_24h(soup),\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"{name} (attempt {attempt}/{retries}) failed: {e}\")\n",
    "            time.sleep(backoff)\n",
    "            backoff *= 2\n",
    "    logger.error(f\"{name} → giving up after {retries} attempts\")\n",
    "    return {\n",
    "        \"crypto_name\":    name,\n",
    "        \"price_usd\":      None,\n",
    "        \"change_24h\":     None,\n",
    "        \"market_cap_usd\": None,\n",
    "        \"volume_24h_usd\": None,\n",
    "    }\n",
    "\n",
    "# ─── MAIN SCRAPER ───────────────────────────────────────────────────────────────\n",
    "def scrape_all(cryptos, max_workers):\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as exe:\n",
    "        futures = {\n",
    "            exe.submit(get_coin_data, name, slug, session): name\n",
    "            for name, slug in cryptos.items()\n",
    "        }\n",
    "        for fut in as_completed(futures):\n",
    "            results.append(fut.result())\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ─── ENTRYPOINT ─────────────────────────────────────────────────────────────────\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Scrape live crypto metrics from CoinGecko\")\n",
    "    parser.add_argument(\"--input-csv\", help=\"CSV with columns crypto_name,slug\")\n",
    "    parser.add_argument(\"--workers\",   type=int, default=5, help=\"Number of threads\")\n",
    "    parser.add_argument(\"--output\",    default=\"crypto_prices.csv\", help=\"Output filename (.csv or .json)\")\n",
    "    args, _ = parser.parse_known_args()  # ignore unexpected flags in Jupyter\n",
    "\n",
    "    if args.input_csv:\n",
    "        df = pd.read_csv(args.input_csv)\n",
    "        cryptos = dict(zip(df[\"crypto_name\"], df[\"slug\"]))\n",
    "    else:\n",
    "        cryptos = {\n",
    "            \"Bitcoin\":      \"bitcoin\",\n",
    "            \"Ethereum\":     \"ethereum\",\n",
    "            \"Solana\":       \"solana\",\n",
    "            \"Cardano\":      \"cardano\",\n",
    "            \"Ripple\":       \"ripple\",\n",
    "            \"Dogecoin\":     \"dogecoin\",\n",
    "            \"Polkadot\":     \"polkadot\",\n",
    "            \"Chainlink\":    \"chainlink\",\n",
    "            \"Litecoin\":     \"litecoin\",\n",
    "            \"Binance Coin\": \"binancecoin\"\n",
    "        }\n",
    "\n",
    "    logger.info(f\"Starting scrape of {len(cryptos)} coins with {args.workers} workers\")\n",
    "    df_out = scrape_all(cryptos, args.workers)\n",
    "\n",
    "    if args.output.endswith(\".json\"):\n",
    "        df_out.to_json(args.output, orient=\"records\", lines=True)\n",
    "    else:\n",
    "        df_out.to_csv(args.output, index=False)\n",
    "\n",
    "    logger.info(f\"Done. Results written to {args.output}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbe84955-f6fa-4c59-bbba-91bb227f6f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    crypto_name     price_usd  change_24h  market_cap_usd  volume_24h_usd\n",
      "0       Bitcoin  95048.000000    0.129847    1.887727e+12    2.705251e+10\n",
      "1      Ethereum   1809.890000    0.167181    2.185740e+11    1.346471e+10\n",
      "2        Solana    148.690000    0.896299    7.700588e+10    3.343215e+09\n",
      "3       Cardano      0.689970   -1.293744    2.486668e+10    6.299620e+08\n",
      "4        Ripple      2.200000   -2.131066    1.287257e+11    2.762327e+09\n",
      "5      Dogecoin      0.175171   -0.247776    2.611191e+10    9.856175e+08\n",
      "6      Polkadot      4.100000   -0.849258    6.248930e+09    1.403477e+08\n",
      "7     Chainlink     14.630000    0.050085    9.612856e+09    3.226683e+08\n",
      "8      Litecoin     84.670000   -0.932678    6.419429e+09    3.343250e+08\n",
      "9  Binance Coin    600.710000   -0.492257    8.765211e+10    7.060881e+08\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# ─── 1) Your coins and their CoinGecko slugs ─────────────────────────────────\n",
    "COINS = {\n",
    "    \"Bitcoin\":      \"bitcoin\",\n",
    "    \"Ethereum\":     \"ethereum\",\n",
    "    \"Solana\":       \"solana\",\n",
    "    \"Cardano\":      \"cardano\",\n",
    "    \"Ripple\":       \"ripple\",\n",
    "    \"Dogecoin\":     \"dogecoin\",\n",
    "    \"Polkadot\":     \"polkadot\",\n",
    "    \"Chainlink\":    \"chainlink\",\n",
    "    \"Litecoin\":     \"litecoin\",\n",
    "    \"Binance Coin\": \"binancecoin\"\n",
    "}\n",
    "\n",
    "# ─── 2) Call the free Simple Price endpoint ────────────────────────────────────\n",
    "url = \"https://api.coingecko.com/api/v3/simple/price\"\n",
    "params = {\n",
    "    \"ids\":           \",\".join(COINS.values()),\n",
    "    \"vs_currencies\": \"usd\",\n",
    "    \"include_24hr_change\":  \"true\",\n",
    "    \"include_market_cap\":   \"true\",\n",
    "    \"include_24hr_vol\":     \"true\"\n",
    "}\n",
    "\n",
    "resp = requests.get(url, params=params)\n",
    "resp.raise_for_status()\n",
    "data = resp.json()\n",
    "\n",
    "# ─── 3) Build a DataFrame from the JSON ────────────────────────────────────────\n",
    "rows = []\n",
    "for name, slug in COINS.items():\n",
    "    info = data.get(slug, {})\n",
    "    rows.append({\n",
    "        \"crypto_name\":    name,\n",
    "        \"price_usd\":      info.get(\"usd\"),\n",
    "        \"change_24h\":     info.get(\"usd_24h_change\"),\n",
    "        \"market_cap_usd\": info.get(\"usd_market_cap\"),\n",
    "        \"volume_24h_usd\": info.get(\"usd_24h_vol\"),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# ─── 4) Save or display ─────────────────────────────────────────────────────────\n",
    "print(df)\n",
    "df.to_csv(\"crypto_prices.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9883664a-7c43-40b2-9228-2b061b548a08",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'reddit_crypto_bulk_tagged.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Your fixed paths:\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m reddit      = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreddit_crypto_bulk_tagged.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m cointele    = pd.read_excel(\u001b[33m\"\u001b[39m\u001b[33mcointelegraph_bitcoin_scroll_fixed.xlsx\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m cryptoslate = pd.read_excel(\u001b[33m\"\u001b[39m\u001b[33mcryptoslate_articles_wpapi.xlsx\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/jupyterlab/4.4.0/libexec/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/jupyterlab/4.4.0/libexec/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/jupyterlab/4.4.0/libexec/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/jupyterlab/4.4.0/libexec/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/jupyterlab/4.4.0/libexec/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'reddit_crypto_bulk_tagged.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Your fixed paths:\n",
    "reddit      = pd.read_csv(\"reddit_crypto_bulk_tagged.csv\")\n",
    "cointele    = pd.read_excel(\"cointelegraph_bitcoin_scroll_fixed.xlsx\")\n",
    "cryptoslate = pd.read_excel(\"cryptoslate_articles_wpapi.xlsx\")\n",
    "prices      = pd.read_csv(\"crypto_prices.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
